{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-16T13:40:16.883765Z",
     "start_time": "2025-03-16T13:40:12.259231Z"
    }
   },
   "source": [
    "from IPython import embed_kernel\n",
    "from pycparser.ply.yacc import token\n",
    "from pygments.lexers.julia import allowed_variable\n",
    "!pip install tiktoken\n",
    "from importlib.metadata import version\n",
    "import tiktoken\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\r\n",
      "  Obtaining dependency information for tiktoken from https://files.pythonhosted.org/packages/12/dd/af27bbe186df481666de48cf0f2f4e0643ba9c78b472e7bf70144c663b22/tiktoken-0.9.0-cp39-cp39-macosx_11_0_arm64.whl.metadata\r\n",
      "  Downloading tiktoken-0.9.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.7 kB)\r\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\r\n",
      "  Obtaining dependency information for regex>=2022.1.18 from https://files.pythonhosted.org/packages/7a/d1/598de10b17fdafc452d11f7dada11c3be4e379a8671393e4e3da3c4070df/regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl.metadata\r\n",
      "  Downloading regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl.metadata (40 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m40.5/40.5 kB\u001B[0m \u001B[31m467.0 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: requests>=2.26.0 in ./.venv/lib/python3.9/site-packages (from tiktoken) (2.32.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\r\n",
      "Downloading tiktoken-0.9.0-cp39-cp39-macosx_11_0_arm64.whl (1.0 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.0/1.0 MB\u001B[0m \u001B[31m3.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl (284 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m284.6/284.6 kB\u001B[0m \u001B[31m9.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: regex, tiktoken\r\n",
      "Successfully installed regex-2024.11.6 tiktoken-0.9.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "tiktoken version: 0.9.0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T13:44:10.874033Z",
     "start_time": "2025-03-16T13:44:10.870560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "text = (\n",
    "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "    \"of someunknownPlace.\"\n",
    ")\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(integers)"
   ],
   "id": "90a12432e6132a16",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T13:44:30.726070Z",
     "start_time": "2025-03-16T13:44:30.723822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "strings = tokenizer.decode(integers)\n",
    "print(strings)"
   ],
   "id": "13d7333750f3de13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T13:48:15.532556Z",
     "start_time": "2025-03-16T13:48:15.524945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    raw_text = file.read()\n",
    "\n",
    "enc_text = tokenizer.encode(raw_text)\n",
    "print(len(enc_text))"
   ],
   "id": "9f964834390045cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T13:50:16.244513Z",
     "start_time": "2025-03-16T13:50:16.231113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "enc_sample = enc_text[50:]\n",
    "\n",
    "context_size = 4\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size+1]\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y:      {y}\")"
   ],
   "id": "8317cd829e8b23f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [290, 4920, 2241, 287]\n",
      "y:      [4920, 2241, 287, 257]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T13:51:17.024923Z",
     "start_time": "2025-03-16T13:51:17.021925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(context, \"---->\", desired)"
   ],
   "id": "ed309f2c1d1cb8b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290] ----> 4920\n",
      "[290, 4920] ----> 2241\n",
      "[290, 4920, 2241] ----> 287\n",
      "[290, 4920, 2241, 287] ----> 257\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T13:51:47.544779Z",
     "start_time": "2025-03-16T13:51:47.542081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"
   ],
   "id": "cc9fee570faaf2c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and ---->  established\n",
      " and established ---->  himself\n",
      " and established himself ---->  in\n",
      " and established himself in ---->  a\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T13:55:32.852856Z",
     "start_time": "2025-03-16T13:55:24.945641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install torch\n",
    "!pip install numpy"
   ],
   "id": "ee803165ec91ecf3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.venv/lib/python3.9/site-packages (2.6.0)\r\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.9/site-packages (from torch) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.9/site-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.9/site-packages (from torch) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.9/site-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.9/site-packages (from torch) (2025.3.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.9/site-packages (from torch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.9/site-packages (from sympy==1.13.1->torch) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.9/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Collecting numpy\r\n",
      "  Obtaining dependency information for numpy from https://files.pythonhosted.org/packages/96/ff/06d1aa3eeb1c614eda245c1ba4fb88c483bee6520d361641331872ac4b82/numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl.metadata\r\n",
      "  Downloading numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl.metadata (60 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m60.9/60.9 kB\u001B[0m \u001B[31m538.4 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl (5.3 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.3/5.3 MB\u001B[0m \u001B[31m2.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: numpy\r\n",
      "Successfully installed numpy-2.0.2\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T13:55:40.567021Z",
     "start_time": "2025-03-16T13:55:40.564911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ],
   "id": "86017489a1a6173f",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T13:59:15.961855Z",
     "start_time": "2025-03-16T13:59:15.958128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GPTDatesetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        \n",
    "        token_ids = tokenizer.encode(txt)\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i+max_length]\n",
    "            target_chunk = token_ids[i+1:i+max_length+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "        "
   ],
   "id": "22619f1a6f2812d8",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T14:01:13.863033Z",
     "start_time": "2025-03-16T14:01:13.860303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatesetV1(txt, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return dataloader"
   ],
   "id": "44b008759d5fcee4",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T14:02:41.992970Z",
     "start_time": "2025-03-16T14:02:41.957046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    raw_text = file.read()\n",
    "\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size=1, max_length=4, stride=1, shuffle=False)\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ],
   "id": "9fdc7d6577adf0bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T14:03:16.424632Z",
     "start_time": "2025-03-16T14:03:16.420519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ],
   "id": "9bb26c85890b35f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T14:07:13.878603Z",
     "start_time": "2025-03-16T14:07:13.840984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataloader_exercise1 = create_dataloader_v1(raw_text, batch_size=1, max_length=2, stride=2, shuffle=False)\n",
    "data_iter = iter(dataloader_exercise1)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)\n",
    "second_batch = next(data_iter)\n",
    "print(second_batch)\n",
    "\n",
    "print(\"----\")\n",
    "\n",
    "dataloader_exercise2 = create_dataloader_v1(raw_text, batch_size=1, max_length=8, stride=2, shuffle=False)\n",
    "data_iter = iter(dataloader_exercise2)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)\n",
    "second_batch = next(data_iter)\n",
    "print(second_batch)\n"
   ],
   "id": "8ab8c094410b59bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 40, 367]]), tensor([[ 367, 2885]])]\n",
      "[tensor([[2885, 1464]]), tensor([[1464, 1807]])]\n",
      "----\n",
      "[tensor([[  40,  367, 2885, 1464, 1807, 3619,  402,  271]]), tensor([[  367,  2885,  1464,  1807,  3619,   402,   271, 10899]])]\n",
      "[tensor([[ 2885,  1464,  1807,  3619,   402,   271, 10899,  2138]]), tensor([[ 1464,  1807,  3619,   402,   271, 10899,  2138,   257]])]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T14:09:19.894546Z",
     "start_time": "2025-03-16T14:09:19.875616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataloader = create_dataloader_v1(\n",
    "raw_text, batch_size=8, max_length=4, stride=4,\n",
    "shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ],
   "id": "5fcfd0f6cb421241",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T14:28:52.151393Z",
     "start_time": "2025-03-16T14:28:52.134572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_ids = torch.tensor([2, 3, 5, 1])\n",
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "print(embedding_layer.weight)"
   ],
   "id": "b07afa9712caf441",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T14:29:26.920220Z",
     "start_time": "2025-03-16T14:29:26.917137Z"
    }
   },
   "cell_type": "code",
   "source": "print(embedding_layer(torch.tensor([3])))",
   "id": "da1f64ea7890dad0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T14:29:48.128318Z",
     "start_time": "2025-03-16T14:29:48.125306Z"
    }
   },
   "cell_type": "code",
   "source": "print(embedding_layer(input_ids))",
   "id": "268a6d1b1e27e6bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T14:36:57.842107Z",
     "start_time": "2025-03-16T14:36:57.695902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ],
   "id": "8fc8253be91c315a",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T14:38:42.410999Z",
     "start_time": "2025-03-16T14:38:42.397442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=max_length, stride=max_length,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Token IDs:\\n\", inputs)\n",
    "print(\"\\nInputs shape:\\n\", inputs.shape)"
   ],
   "id": "ae803848453040bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Inputs shape:\n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T14:46:00.849029Z",
     "start_time": "2025-03-16T14:46:00.844426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(\"Token embeddings shape:\\n\", token_embeddings.shape)\n",
    "print(\"Token embeddings:\\n\", token_embeddings[:5])"
   ],
   "id": "5c1271e33ea38c6d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embeddings shape:\n",
      " torch.Size([8, 4, 256])\n",
      "Token embeddings:\n",
      " tensor([[[ 0.4913,  1.1239,  1.4588,  ..., -0.3995, -1.8735, -0.1445],\n",
      "         [ 0.4481,  0.2536, -0.2655,  ...,  0.4997, -1.1991, -1.1844],\n",
      "         [-0.2507, -0.0546,  0.6687,  ...,  0.9618,  2.3737, -0.0528],\n",
      "         [ 0.9457,  0.8657,  1.6191,  ..., -0.4544, -0.7460,  0.3483]],\n",
      "\n",
      "        [[ 1.5460,  1.7368, -0.7848,  ..., -0.1004,  0.8584, -0.3421],\n",
      "         [-1.8622, -0.1914, -0.3812,  ...,  1.1220, -0.3496,  0.6091],\n",
      "         [ 1.9847, -0.6483, -0.1415,  ..., -0.3841, -0.9355,  1.4478],\n",
      "         [ 0.9647,  1.2974, -1.6207,  ...,  1.1463,  1.5797,  0.3969]],\n",
      "\n",
      "        [[-0.7713,  0.6572,  0.1663,  ..., -0.8044,  0.0542,  0.7426],\n",
      "         [ 0.8046,  0.5047,  1.2922,  ...,  1.4648,  0.4097,  0.3205],\n",
      "         [ 0.0795, -1.7636,  0.5750,  ...,  2.1823,  1.8231, -0.3635],\n",
      "         [ 0.4267, -0.0647,  0.5686,  ..., -0.5209,  1.3065,  0.8473]],\n",
      "\n",
      "        [[ 0.4256, -0.2887, -1.1954,  ..., -1.1536,  1.8305, -0.1415],\n",
      "         [-0.4073, -0.6186,  0.5848,  ..., -1.4015,  0.4552, -1.3788],\n",
      "         [-0.8517, -0.1434,  0.3774,  ..., -0.6284, -0.1558, -0.9530],\n",
      "         [ 0.0795, -1.7636,  0.5750,  ...,  2.1823,  1.8231, -0.3635]],\n",
      "\n",
      "        [[ 0.2710,  0.2873, -0.8637,  ..., -2.9907, -1.5801, -1.2537],\n",
      "         [ 1.1145, -0.1559, -1.5748,  ..., -0.0308,  1.7634,  0.9578],\n",
      "         [-0.1970, -0.6008, -0.9816,  ..., -0.7924, -0.2149,  0.6119],\n",
      "         [-0.4073, -0.6186,  0.5848,  ..., -1.4015,  0.4552, -1.3788]]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T14:46:31.310304Z",
     "start_time": "2025-03-16T14:46:31.305599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
    "print(\"Position embeddings shape:\\n\", pos_embeddings.shape)\n",
    "print(\"Position embeddings:\\n\", pos_embeddings[:5])"
   ],
   "id": "51975038ca49fe20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position embeddings shape:\n",
      " torch.Size([4, 256])\n",
      "Position embeddings:\n",
      " tensor([[-0.8194,  0.5543, -0.8290,  ...,  0.1325,  0.2115,  0.3610],\n",
      "        [ 0.4193, -0.9461, -0.3407,  ...,  0.7930,  1.7009,  0.5663],\n",
      "        [-0.2362, -1.7187, -1.0489,  ...,  1.1218,  0.2796,  0.9912],\n",
      "        [-0.9549,  0.4699,  0.2580,  ..., -1.3689,  1.6505,  1.3488]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T14:42:05.425187Z",
     "start_time": "2025-03-16T14:42:05.421511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(\"Input embeddings shape:\\n\", input_embeddings.shape)"
   ],
   "id": "c3e0bf9efffc4ca8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input embeddings shape:\n",
      " torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "58ea08c80c7e9976"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
